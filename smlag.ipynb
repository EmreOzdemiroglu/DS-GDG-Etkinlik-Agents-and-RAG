{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SmolAgents Rehber\n",
    "\n",
    "- Setup -> huggingface-cli login\n",
    "- Basit Search \n",
    "- Smol Agents Yapısı\n",
    "- Tools\n",
    "- Agent Memory\n",
    "- Model Ekleme (LiteLLM, Ollama, Gemini)\n",
    "- Multi agent system\n",
    "- AgenticRAG\n",
    "- Secure Code Execution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basit Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, WebSearchTool, InferenceClientModel, ToolCallingAgent, HfApiModel, DuckDuckGoSearchTool, LiteLLMModel\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InferenceClientModel()\n",
    "agent = CodeAgent(tools=[WebSearchTool()], model=model)\n",
    "#agent = CodeAgent(tools=[WebSearchTool()], model=model, planning_interval=3) \n",
    "\n",
    "agent.run(\"How long it takes to a cheetah to run from TBMM (In Turkey) to MEF University\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Ekleme (LiteLLM, Ollama, Gemini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HfApiModel(model_id=\"Qwen/Qwen2.5-Coder-32B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LiteLLMModel(\n",
    "    model_id=\"gemini/gemini-2.0-flash\",\n",
    "    api_key=os.getenv(\"GEMINI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LiteLLMModel(\n",
    "    model_id=\"ollama/gemma3:latest\",\n",
    "    api_base=\"http://localhost:11434\",  # Adjust if using a remote server\n",
    "    api_key=\"ollama\"  # Replace with your API key if required\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ToolCallingAgent(tools=[DuckDuckGoSearchTool()], model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = CodeAgent(tools=[DuckDuckGoSearchTool()], model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "answer = agent.run(\"Could you get me the title of the page at url 'https://huggingface.co/blog'?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Agent System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, ToolCallingAgent, DuckDuckGoSearchTool, LiteLLMModel, tool\n",
    "\n",
    "from typing import Optional\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the model with Gemini API\n",
    "model = LiteLLMModel(\n",
    "    model_id=\"gemini/gemini-2.0-flash\",\n",
    "    api_key=os.getenv(\"GEMINI_API_KEY\")\n",
    ")\n",
    "@tool\n",
    "def get_coordinates(location: str) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve latitude and longitude for a specified location using Nominatim API.\n",
    "    \n",
    "    Args:\n",
    "        location (str): The location to fetch coordinates for.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing latitude and longitude, or an error message if unsuccessful.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        url = f\"https://nominatim.openstreetmap.org/search?format=json&q={location}&limit=1\"\n",
    "        headers = {'User-Agent': 'SmolAgentsWeatherApp/1.0'}\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data and len(data) > 0:\n",
    "                return {\"latitude\": float(data[0][\"lat\"]), \"longitude\": float(data[0][\"lon\"])}\n",
    "            return {\"error\": f\"No coordinates found for {location}\"}\n",
    "        return {\"error\": f\"API error: {response.status_code}\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error fetching coordinates for {location}: {str(e)}\"}\n",
    "\n",
    "@tool\n",
    "def get_weather(location: str, celsius: Optional[bool] = True) -> str:\n",
    "    \"\"\"\n",
    "    Fetch current weather information for a given location using Open-Meteo API.\n",
    "    \n",
    "    Args:\n",
    "        location (str): The location to get weather information for.\n",
    "        celsius (bool, optional): Use Celsius for temperature if True, Fahrenheit if False. Defaults to True.\n",
    "    \n",
    "    Returns:\n",
    "        str: A formatted string with weather details or an error message with fallback dummy data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        coords = get_coordinates(location)\n",
    "        if \"error\" in coords:\n",
    "            unit = '°C' if celsius else '°F'\n",
    "            temp = '7°C' if celsius else '45°F'\n",
    "            return f\"Could not retrieve coordinates for {location}: {coords['error']}. Falling back to dummy data: The weather in {location} is sunny with temperatures around {temp}.\"\n",
    "\n",
    "        latitude = coords[\"latitude\"]\n",
    "        longitude = coords[\"longitude\"]\n",
    "\n",
    "        url = f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,relative_humidity_2m,rain,weather_code\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if 'current' in data:\n",
    "                temp = data['current']['temperature_2m']\n",
    "                humidity = data['current']['relative_humidity_2m']\n",
    "                rain = data['current']['rain']\n",
    "                weather_code = data['current']['weather_code']\n",
    "                \n",
    "                weather_desc = {\n",
    "                    0: \"clear sky\", 1: \"mainly clear\", 2: \"partly cloudy\", 3: \"overcast\",\n",
    "                    45: \"fog\", 51: \"light drizzle\", 61: \"light rain\", 63: \"moderate rain\",\n",
    "                    65: \"heavy rain\", 71: \"light snow\", 73: \"moderate snow\", 75: \"heavy snow\",\n",
    "                    80: \"rain showers\", 95: \"thunderstorm\"\n",
    "                }.get(weather_code, \"unknown weather condition\")\n",
    "                \n",
    "                unit = \"°C\" if celsius else \"°F\"\n",
    "                if not celsius:\n",
    "                    temp = (temp * 9/5) + 32\n",
    "                \n",
    "                return f\"The weather in {location} is {weather_desc} with a temperature of {temp:.1f}{unit}, humidity at {humidity}%, and rain at {rain}mm.\"\n",
    "            return f\"Could not retrieve weather data for {location}. No current data available.\"\n",
    "        return f\"Could not retrieve weather data for {location}. API error: {response.status_code}\"\n",
    "    except Exception as e:\n",
    "        unit = '°C' if celsius else '°F'\n",
    "        temp = '7°C' if celsius else '45°F'\n",
    "        return f\"Error fetching weather data for {location}: {str(e)}. Falling back to dummy data: The weather in {location} is sunny with temperatures around {temp}.\"\n",
    "\n",
    "# Initialize the agent with weather and coordinates tools\n",
    "web_agent = ToolCallingAgent(\n",
    "    tools=[DuckDuckGoSearchTool()], \n",
    "    model=model,\n",
    "    name=\"web_agent\",\n",
    "    description=\"Runs web searches. Give it your query as an argument.\",\n",
    "    )\n",
    "weather_agent = ToolCallingAgent(\n",
    "    tools=[get_weather, get_coordinates],\n",
    "    model=model,\n",
    "    name=\"weather_agent\",\n",
    "    description=\"Gets weather information for a given location. Give it the location as an argument.\",\n",
    "    )\n",
    "\n",
    "manager_agent = CodeAgent(\n",
    "    tools=[],\n",
    "    model=model,\n",
    "    managed_agents=[weather_agent, web_agent],\n",
    "    additional_authorized_imports=[\"time\", \"numpy\", \"pandas\"],\n",
    ")\n",
    "# Run the agent to compare temperatures in different locations\n",
    "#answer = web_agent.run(\"What is hotter right now? Istanbul or Brazil and also right now which country is the hottest?\")\n",
    "answer = manager_agent.run(\"What is hotter right now? Istanbul or Brazil and also right now which country is the hottest?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEMORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import ActionStep\n",
    "\n",
    "system_prompt_step = agent.memory.system_prompt\n",
    "print(\"The system prompt given to the agent was:\")\n",
    "print(system_prompt_step.system_prompt)\n",
    "\n",
    "task_step = agent.memory.steps[0]\n",
    "print(\"\\n\\nThe first task step was:\")\n",
    "print(task_step.task)\n",
    "\n",
    "for step in agent.memory.steps:\n",
    "    if isinstance(step, ActionStep):\n",
    "        if step.error is not None:\n",
    "            print(f\"\\nStep {step.step_number} got this error:\\n{step.error}\\n\")\n",
    "        else:\n",
    "            print(f\"\\nStep {step.step_number} got these observations:\\n{step.observations}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install smolagents pandas langchain langchain-community sentence-transformers datasets python-dotenv rank_bm25 --upgrade -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 2647/2647 [00:00<00:00, 7904.67 examples/s]\n",
      "Filter: 100%|██████████| 2647/2647 [00:00<00:00, 84850.95 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "knowledge_base = datasets.load_dataset(\"m-ric/huggingface_doc\", split=\"train\")\n",
    "knowledge_base = knowledge_base.filter(lambda row: row[\"source\"].startswith(\"huggingface/transformers\"))\n",
    "\n",
    "source_docs = [\n",
    "    Document(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"].split(\"/\")[1]})\n",
    "    for doc in knowledge_base\n",
    "]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    add_start_index=True,\n",
    "    strip_whitespace=True,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    ")\n",
    "docs_processed = text_splitter.split_documents(source_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import Tool\n",
    "\n",
    "class RetrieverTool(Tool):\n",
    "    name = \"retriever\"\n",
    "    description = \"Uses semantic search to retrieve the parts of transformers documentation that could be most relevant to answer your query.\"\n",
    "    inputs = {\n",
    "        \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The query to perform. This should be semantically close to your target documents. Use the affirmative form rather than a question.\",\n",
    "        }\n",
    "    }\n",
    "    output_type = \"string\"\n",
    "\n",
    "    def __init__(self, docs, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.retriever = BM25Retriever.from_documents(\n",
    "            docs, k=10\n",
    "        )\n",
    "\n",
    "    def forward(self, query: str) -> str:\n",
    "        assert isinstance(query, str), \"Your search query must be a string\"\n",
    "\n",
    "        docs = self.retriever.invoke(\n",
    "            query,\n",
    "        )\n",
    "        return \"\\nRetrieved documents:\\n\" + \"\".join(\n",
    "            [\n",
    "                f\"\\n\\n===== Document {str(i)} =====\\n\" + doc.page_content\n",
    "                for i, doc in enumerate(docs)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "retriever_tool = RetrieverTool(docs_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = CodeAgent(\n",
    "    tools=[retriever_tool], model=model, max_steps=4, verbosity_level=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_output = agent.run(\"For a transformers model training, which is slower, the forward or the backward pass?\")\n",
    "\n",
    "print(\"Final output:\")\n",
    "print(agent_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
